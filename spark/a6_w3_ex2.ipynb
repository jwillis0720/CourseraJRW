{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Welcome to exercise twp of week three of “Apache Spark for Scalable Machine Learning on BigData”. In this exercise we’ll work on clustering.\n",
    "\n",
    "Let’s create our DataFrame again:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T07:52:31.930109Z",
     "start_time": "2019-12-10T07:52:28.567698Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "conf = SparkConf()\n",
    "\n",
    "sc = SparkContext(conf=conf)\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T07:52:46.142297Z",
     "start_time": "2019-12-10T07:52:43.299572Z"
    }
   },
   "outputs": [],
   "source": [
    "# delete files from previous runs\n",
    "#!rm -f hmp.parquet*\n",
    "\n",
    "# download the file containing the data in PARQUET format\n",
    "#!wget https://github.com/IBM/coursera/raw/master/hmp.parquet\n",
    "    \n",
    "# create a dataframe out of it\n",
    "df = spark.read.parquet('hmp.parquet')\n",
    "\n",
    "# register a corresponding query table\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s reuse our feature engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T07:52:50.434143Z",
     "start_time": "2019-12-10T07:52:48.208754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\n",
      "|  x|  y|  z|              source|      class|classIndex|   categoryVec|        features|       features_norm|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|\n",
      "| 22| 49| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,49.0,35.0]|[0.20754716981132...|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|\n",
      "| 22| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,35.0]|[0.20183486238532...|\n",
      "| 21| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,52.0,34.0]|[0.19626168224299...|\n",
      "| 22| 51| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,34.0]|[0.20560747663551...|\n",
      "| 20| 50| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,35.0]|[0.19047619047619...|\n",
      "| 22| 52| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,52.0,34.0]|[0.20370370370370...|\n",
      "| 22| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,50.0,34.0]|[0.20754716981132...|\n",
      "| 22| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[22.0,51.0,35.0]|[0.20370370370370...|\n",
      "| 21| 51| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,51.0,33.0]|[0.2,0.4857142857...|\n",
      "| 20| 50| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,50.0,34.0]|[0.19230769230769...|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|\n",
      "| 21| 49| 33|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[21.0,49.0,33.0]|[0.20388349514563...|\n",
      "| 20| 51| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[20.0,51.0,35.0]|[0.18867924528301...|\n",
      "| 18| 49| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,49.0,34.0]|[0.17821782178217...|\n",
      "| 19| 48| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[19.0,48.0,34.0]|[0.18811881188118...|\n",
      "| 16| 53| 34|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[16.0,53.0,34.0]|[0.15533980582524...|\n",
      "| 18| 52| 35|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,52.0,35.0]|[0.17142857142857...|\n",
      "| 18| 51| 32|Accelerometer-201...|Brush_teeth|       6.0|(13,[6],[1.0])|[18.0,51.0,32.0]|[0.17821782178217...|\n",
      "+---+---+---+--------------------+-----------+----------+--------------+----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler, Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"classIndex\")\n",
    "encoder = OneHotEncoder(inputCol=\"classIndex\", outputCol=\"categoryVec\")\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"x\",\"y\",\"z\"],\n",
    "                                  outputCol=\"features\")\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"features_norm\", p=1.0)\n",
    "\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer])\n",
    "model = pipeline.fit(df)\n",
    "prediction = model.transform(df)\n",
    "prediction.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s create a new pipeline for kmeans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T07:58:34.689537Z",
     "start_time": "2019-12-10T07:58:24.950611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.2668998965895519\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"features\").setK(14).setSeed(1)\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer ,kmeans])\n",
    "model = pipeline.fit(df)\n",
    "predictions = model.transform(df)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 14 different movement patterns in the dataset, so setting K of KMeans to 14 is a good idea. But please experiment with different values for K, do you find a sweet spot? The closer Silhouette gets to 1, the better.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Silhouette_(clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T07:58:15.547964Z",
     "start_time": "2019-12-10T07:56:52.198340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 2 and Silhouette with squared euclidean distance = 0.6875664014387497\n",
      "K = 3 and Silhouette with squared euclidean distance = 0.6147915951361759\n",
      "K = 4 and Silhouette with squared euclidean distance = 0.6333227654128869\n",
      "K = 5 and Silhouette with squared euclidean distance = 0.5937447997439024\n",
      "K = 6 and Silhouette with squared euclidean distance = 0.592463658820136\n",
      "K = 7 and Silhouette with squared euclidean distance = 0.5484627422401509\n",
      "K = 8 and Silhouette with squared euclidean distance = 0.46686489256383346\n",
      "K = 9 and Silhouette with squared euclidean distance = 0.48034893889849645\n",
      "K = 10 and Silhouette with squared euclidean distance = 0.47370428136987536\n",
      "K = 11 and Silhouette with squared euclidean distance = 0.4819049717562352\n",
      "K = 12 and Silhouette with squared euclidean distance = 0.40964155503229643\n",
      "K = 13 and Silhouette with squared euclidean distance = 0.4153293521373778\n",
      "K = 14 and Silhouette with squared euclidean distance = 0.41244594513295846\n"
     ]
    }
   ],
   "source": [
    "for k in range(2,15):\n",
    "    kmeans = KMeans(featuresCol=\"features\").setK(k).setSeed(1)\n",
    "    pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer ,kmeans])\n",
    "    model = pipeline.fit(df)\n",
    "    predictions = model.transform(df)\n",
    "\n",
    "    evaluator = ClusteringEvaluator()\n",
    "\n",
    "    silhouette = evaluator.evaluate(predictions)\n",
    "    print(\"K = {} and Silhouette with squared euclidean distance = {}\".format(k,silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now please extend the pipeline to work on the normalized features. You need to tell KMeans to use the normalized feature column and change the pipeline in order to contain the normalizer stage as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T08:50:46.970451Z",
     "start_time": "2019-12-10T08:05:16.811870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.2668998965895519\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(featuresCol='features_norm').setK(14).setSeed(1)\n",
    "pipeline = Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer ,kmeans])\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "predictions = model.transform(df)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))\n",
    "df_pan = predictions.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, inflating the dataset helps, here we multiply x by 10, let’s see if the performance inceases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T08:50:47.050285Z",
     "start_time": "2019-12-10T08:50:46.987271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>source</th>\n",
       "      <th>class</th>\n",
       "      <th>classIndex</th>\n",
       "      <th>categoryVec</th>\n",
       "      <th>features</th>\n",
       "      <th>features_norm</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>Accelerometer-2011-04-11-13-28-18-brush_teeth-...</td>\n",
       "      <td>Brush_teeth</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[22.0, 49.0, 35.0]</td>\n",
       "      <td>[0.20754716981132076, 0.46226415094339623, 0.3...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>Accelerometer-2011-04-11-13-28-18-brush_teeth-...</td>\n",
       "      <td>Brush_teeth</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[22.0, 49.0, 35.0]</td>\n",
       "      <td>[0.20754716981132076, 0.46226415094339623, 0.3...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>Accelerometer-2011-04-11-13-28-18-brush_teeth-...</td>\n",
       "      <td>Brush_teeth</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[22.0, 52.0, 35.0]</td>\n",
       "      <td>[0.2018348623853211, 0.47706422018348627, 0.32...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>Accelerometer-2011-04-11-13-28-18-brush_teeth-...</td>\n",
       "      <td>Brush_teeth</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[22.0, 52.0, 35.0]</td>\n",
       "      <td>[0.2018348623853211, 0.47706422018348627, 0.32...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>52</td>\n",
       "      <td>34</td>\n",
       "      <td>Accelerometer-2011-04-11-13-28-18-brush_teeth-...</td>\n",
       "      <td>Brush_teeth</td>\n",
       "      <td>6.0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...</td>\n",
       "      <td>[21.0, 52.0, 34.0]</td>\n",
       "      <td>[0.19626168224299065, 0.48598130841121495, 0.3...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446524</th>\n",
       "      <td>41</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>Accelerometer-2012-06-11-11-39-29-walk-m1.txt</td>\n",
       "      <td>Walk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[41.0, 35.0, 51.0]</td>\n",
       "      <td>[0.3228346456692913, 0.2755905511811024, 0.401...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446525</th>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>Accelerometer-2012-06-11-11-39-29-walk-m1.txt</td>\n",
       "      <td>Walk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[40.0, 35.0, 52.0]</td>\n",
       "      <td>[0.31496062992125984, 0.2755905511811024, 0.40...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446526</th>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>51</td>\n",
       "      <td>Accelerometer-2012-06-11-11-39-29-walk-m1.txt</td>\n",
       "      <td>Walk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[39.0, 37.0, 51.0]</td>\n",
       "      <td>[0.30708661417322836, 0.29133858267716534, 0.4...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446527</th>\n",
       "      <td>39</td>\n",
       "      <td>37</td>\n",
       "      <td>53</td>\n",
       "      <td>Accelerometer-2012-06-11-11-39-29-walk-m1.txt</td>\n",
       "      <td>Walk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[39.0, 37.0, 53.0]</td>\n",
       "      <td>[0.3023255813953488, 0.2868217054263566, 0.410...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446528</th>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "      <td>51</td>\n",
       "      <td>Accelerometer-2012-06-11-11-39-29-walk-m1.txt</td>\n",
       "      <td>Walk</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[39.0, 35.0, 51.0]</td>\n",
       "      <td>[0.312, 0.28, 0.408]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446529 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         x   y   z                                             source  \\\n",
       "0       22  49  35  Accelerometer-2011-04-11-13-28-18-brush_teeth-...   \n",
       "1       22  49  35  Accelerometer-2011-04-11-13-28-18-brush_teeth-...   \n",
       "2       22  52  35  Accelerometer-2011-04-11-13-28-18-brush_teeth-...   \n",
       "3       22  52  35  Accelerometer-2011-04-11-13-28-18-brush_teeth-...   \n",
       "4       21  52  34  Accelerometer-2011-04-11-13-28-18-brush_teeth-...   \n",
       "...     ..  ..  ..                                                ...   \n",
       "446524  41  35  51      Accelerometer-2012-06-11-11-39-29-walk-m1.txt   \n",
       "446525  40  35  52      Accelerometer-2012-06-11-11-39-29-walk-m1.txt   \n",
       "446526  39  37  51      Accelerometer-2012-06-11-11-39-29-walk-m1.txt   \n",
       "446527  39  37  53      Accelerometer-2012-06-11-11-39-29-walk-m1.txt   \n",
       "446528  39  35  51      Accelerometer-2012-06-11-11-39-29-walk-m1.txt   \n",
       "\n",
       "              class  classIndex  \\\n",
       "0       Brush_teeth         6.0   \n",
       "1       Brush_teeth         6.0   \n",
       "2       Brush_teeth         6.0   \n",
       "3       Brush_teeth         6.0   \n",
       "4       Brush_teeth         6.0   \n",
       "...             ...         ...   \n",
       "446524         Walk         0.0   \n",
       "446525         Walk         0.0   \n",
       "446526         Walk         0.0   \n",
       "446527         Walk         0.0   \n",
       "446528         Walk         0.0   \n",
       "\n",
       "                                              categoryVec            features  \\\n",
       "0       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  [22.0, 49.0, 35.0]   \n",
       "1       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  [22.0, 49.0, 35.0]   \n",
       "2       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  [22.0, 52.0, 35.0]   \n",
       "3       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  [22.0, 52.0, 35.0]   \n",
       "4       (0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, ...  [21.0, 52.0, 34.0]   \n",
       "...                                                   ...                 ...   \n",
       "446524  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [41.0, 35.0, 51.0]   \n",
       "446525  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [40.0, 35.0, 52.0]   \n",
       "446526  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [39.0, 37.0, 51.0]   \n",
       "446527  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [39.0, 37.0, 53.0]   \n",
       "446528  (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [39.0, 35.0, 51.0]   \n",
       "\n",
       "                                            features_norm  prediction  \n",
       "0       [0.20754716981132076, 0.46226415094339623, 0.3...          12  \n",
       "1       [0.20754716981132076, 0.46226415094339623, 0.3...          12  \n",
       "2       [0.2018348623853211, 0.47706422018348627, 0.32...          12  \n",
       "3       [0.2018348623853211, 0.47706422018348627, 0.32...          12  \n",
       "4       [0.19626168224299065, 0.48598130841121495, 0.3...          10  \n",
       "...                                                   ...         ...  \n",
       "446524  [0.3228346456692913, 0.2755905511811024, 0.401...           2  \n",
       "446525  [0.31496062992125984, 0.2755905511811024, 0.40...           2  \n",
       "446526  [0.30708661417322836, 0.29133858267716534, 0.4...           8  \n",
       "446527  [0.3023255813953488, 0.2868217054263566, 0.410...           8  \n",
       "446528                               [0.312, 0.28, 0.408]           2  \n",
       "\n",
       "[446529 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "df_denormalized = df.select([col('*'),(col('x')*10)]).drop('x').withColumnRenamed('(x * 10)','x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T08:01:36.687093Z",
     "start_time": "2019-12-10T08:01:36.672499Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_denormalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-fb0b03f94edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features_norm\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictionCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'classIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetSeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvectorAssembler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_denormalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_denormalized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_denormalized' is not defined"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(featuresCol=\"features_norm\").setK(14).setSeed(1)\n",
    "pipeline = Pipeline(stages=[vectorAssembler, kmeans])\n",
    "model = pipeline.fit(df_denormalized)\n",
    "predictions = model.transform(df_denormalized)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apache SparkML can be used to try many different algorithms and parametrizations using the same pipeline. Please change the code below to use GaussianMixture over KMeans. Please use the following link for your reference.\n",
    "\n",
    "https://spark.apache.org/docs/latest/ml-clustering.html#gaussian-mixture-model-gmm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import GaussianMixture\n",
    "\n",
    "gmm = $$\n",
    "pipeline =  Pipeline(stages=[vectorAssembler, gmm])\n",
    "\n",
    "\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "predictions = model.transform(df)\n",
    "\n",
    "evaluator = ClusteringEvaluator()\n",
    "\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T08:50:47.063153Z",
     "start_time": "2019-12-10T08:50:47.056670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `GaussianMixture` not found.\n"
     ]
    }
   ],
   "source": [
    "GaussianMixture?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
